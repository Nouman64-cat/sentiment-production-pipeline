"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[653],{5680(e,t,n){n.d(t,{xA:()=>g,yg:()=>y});var a=n(6540);function l(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter(function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable})),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach(function(t){l(e,t,n[t])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach(function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))})}return e}function o(e,t){if(null==e)return{};var n,a,l=function(e,t){if(null==e)return{};var n,a,l={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(l[n]=e[n]);return l}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(l[n]=e[n])}return l}var p=a.createContext({}),s=function(e){var t=a.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},g=function(e){var t=s(e.components);return a.createElement(p.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef(function(e,t){var n=e.components,l=e.mdxType,r=e.originalType,p=e.parentName,g=o(e,["components","mdxType","originalType","parentName"]),m=s(n),y=l,u=m["".concat(p,".").concat(y)]||m[y]||d[y]||r;return n?a.createElement(u,i(i({ref:t},g),{},{components:n})):a.createElement(u,i({ref:t},g))});function y(e,t){var n=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var r=n.length,i=new Array(r);i[0]=m;var o={};for(var p in t)hasOwnProperty.call(t,p)&&(o[p]=t[p]);o.originalType=e,o.mdxType="string"==typeof e?e:l,i[1]=o;for(var s=2;s<r;s++)i[s]=n[s];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},8964(e,t,n){n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>d,frontMatter:()=>r,metadata:()=>o,toc:()=>s});var a=n(8168),l=(n(6540),n(5680));const r={sidebar_position:8},i="API Usage",o={unversionedId:"api-usage",id:"api-usage",title:"API Usage",description:"Complete documentation for the Sentiment Analysis REST API endpoints with example requests.",source:"@site/docs/api-usage.md",sourceDirName:".",slug:"/api-usage",permalink:"/sentiment-production-pipeline/docs/api-usage",draft:!1,editUrl:"https://github.com/Nouman64-cat/sentiment-production-pipeline/tree/main/docs/docs/api-usage.md",tags:[],version:"current",sidebarPosition:8,frontMatter:{sidebar_position:8},sidebar:"tutorialSidebar",previous:{title:"Evaluation & Metrics",permalink:"/sentiment-production-pipeline/docs/evaluation"}},p={},s=[{value:"Base URL",id:"base-url",level:2},{value:"Authentication",id:"authentication",level:2},{value:"Endpoints",id:"endpoints",level:2},{value:"Health Check",id:"health-check",level:3},{value:"Response",id:"response",level:4},{value:"Example",id:"example",level:4},{value:"Predict with ML Model",id:"predict-with-ml-model",level:3},{value:"Request Body",id:"request-body",level:4},{value:"Response",id:"response-1",level:4},{value:"Example",id:"example-1",level:4},{value:"Predict with DL Model",id:"predict-with-dl-model",level:3},{value:"Request Body",id:"request-body-1",level:4},{value:"Response",id:"response-2",level:4},{value:"Example",id:"example-2",level:4},{value:"Error Handling",id:"error-handling",level:2},{value:"Model Not Available",id:"model-not-available",level:3},{value:"Invalid Request",id:"invalid-request",level:3},{value:"Batch Processing Example",id:"batch-processing-example",level:2},{value:"OpenAPI Documentation",id:"openapi-documentation",level:2},{value:"Rate Limiting",id:"rate-limiting",level:2},{value:"Response Times",id:"response-times",level:2},{value:"SDK Examples",id:"sdk-examples",level:2},{value:"Python Client Class",id:"python-client-class",level:3},{value:"JavaScript/TypeScript Client",id:"javascripttypescript-client",level:3}],g={toc:s};function d({components:e,...t}){return(0,l.yg)("wrapper",(0,a.A)({},g,t,{components:e,mdxType:"MDXLayout"}),(0,l.yg)("h1",{id:"api-usage"},"API Usage"),(0,l.yg)("p",null,"Complete documentation for the Sentiment Analysis REST API endpoints with example requests."),(0,l.yg)("h2",{id:"base-url"},"Base URL"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"http://localhost:8000\n")),(0,l.yg)("p",null,"For production deployments, replace with your deployed URL."),(0,l.yg)("h2",{id:"authentication"},"Authentication"),(0,l.yg)("p",null,"Currently, the API does not require authentication. For production, implement API key or OAuth2 authentication."),(0,l.yg)("h2",{id:"endpoints"},"Endpoints"),(0,l.yg)("h3",{id:"health-check"},"Health Check"),(0,l.yg)("p",null,"Check the status of the API and loaded models."),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-http"},"GET /healthcheck\n")),(0,l.yg)("h4",{id:"response"},"Response"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "status": "ok",\n  "ml_model": true,\n  "dl_model": true\n}\n')),(0,l.yg)("table",null,(0,l.yg)("thead",{parentName:"table"},(0,l.yg)("tr",{parentName:"thead"},(0,l.yg)("th",{parentName:"tr",align:null},"Field"),(0,l.yg)("th",{parentName:"tr",align:null},"Type"),(0,l.yg)("th",{parentName:"tr",align:null},"Description"))),(0,l.yg)("tbody",{parentName:"table"},(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("inlineCode",{parentName:"td"},"status")),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},'API status ("ok" or "error")')),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("inlineCode",{parentName:"td"},"ml_model")),(0,l.yg)("td",{parentName:"tr",align:null},"boolean"),(0,l.yg)("td",{parentName:"tr",align:null},"Whether ML model is loaded")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("inlineCode",{parentName:"td"},"dl_model")),(0,l.yg)("td",{parentName:"tr",align:null},"boolean"),(0,l.yg)("td",{parentName:"tr",align:null},"Whether DL model is loaded")))),(0,l.yg)("h4",{id:"example"},"Example"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-bash"},"curl http://localhost:8000/healthcheck\n")),(0,l.yg)("hr",null),(0,l.yg)("h3",{id:"predict-with-ml-model"},"Predict with ML Model"),(0,l.yg)("p",null,"Analyze sentiment using the Classical Machine Learning model (Logistic Regression)."),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-http"},"POST /predict-ml\nContent-Type: application/json\n")),(0,l.yg)("h4",{id:"request-body"},"Request Body"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "text": "This product is absolutely amazing! I love it."\n}\n')),(0,l.yg)("table",null,(0,l.yg)("thead",{parentName:"table"},(0,l.yg)("tr",{parentName:"thead"},(0,l.yg)("th",{parentName:"tr",align:null},"Field"),(0,l.yg)("th",{parentName:"tr",align:null},"Type"),(0,l.yg)("th",{parentName:"tr",align:null},"Required"),(0,l.yg)("th",{parentName:"tr",align:null},"Description"))),(0,l.yg)("tbody",{parentName:"table"},(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("inlineCode",{parentName:"td"},"text")),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"Yes"),(0,l.yg)("td",{parentName:"tr",align:null},"Text to analyze")))),(0,l.yg)("h4",{id:"response-1"},"Response"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "prediction": "positive",\n  "inference_time_ms": 0.45,\n  "model": "LogisticRegression"\n}\n')),(0,l.yg)("table",null,(0,l.yg)("thead",{parentName:"table"},(0,l.yg)("tr",{parentName:"thead"},(0,l.yg)("th",{parentName:"tr",align:null},"Field"),(0,l.yg)("th",{parentName:"tr",align:null},"Type"),(0,l.yg)("th",{parentName:"tr",align:null},"Description"))),(0,l.yg)("tbody",{parentName:"table"},(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("inlineCode",{parentName:"td"},"prediction")),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},'"positive" or "negative"')),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("inlineCode",{parentName:"td"},"inference_time_ms")),(0,l.yg)("td",{parentName:"tr",align:null},"float"),(0,l.yg)("td",{parentName:"tr",align:null},"Time taken for inference")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("inlineCode",{parentName:"td"},"model")),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"Model used for prediction")))),(0,l.yg)("h4",{id:"example-1"},"Example"),(0,l.yg)("p",null,(0,l.yg)("strong",{parentName:"p"},"cURL:")),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-bash"},'curl -X POST http://localhost:8000/predict-ml \\\n  -H "Content-Type: application/json" \\\n  -d \'{"text": "This product is absolutely amazing! I love it."}\'\n')),(0,l.yg)("p",null,(0,l.yg)("strong",{parentName:"p"},"Python:")),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-python"},"import requests\n\nresponse = requests.post(\n    \"http://localhost:8000/predict-ml\",\n    json={\"text\": \"This product is absolutely amazing! I love it.\"}\n)\nprint(response.json())\n# {'prediction': 'positive', 'inference_time_ms': 0.45, 'model': 'LogisticRegression'}\n")),(0,l.yg)("p",null,(0,l.yg)("strong",{parentName:"p"},"JavaScript:")),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-javascript"},'const response = await fetch("http://localhost:8000/predict-ml", {\n  method: "POST",\n  headers: { "Content-Type": "application/json" },\n  body: JSON.stringify({\n    text: "This product is absolutely amazing! I love it.",\n  }),\n});\nconst data = await response.json();\nconsole.log(data);\n// {prediction: \'positive\', inference_time_ms: 0.45, model: \'LogisticRegression\'}\n')),(0,l.yg)("hr",null),(0,l.yg)("h3",{id:"predict-with-dl-model"},"Predict with DL Model"),(0,l.yg)("p",null,"Analyze sentiment using the Deep Learning model (DistilBERT)."),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-http"},"POST /predict-dl\nContent-Type: application/json\n")),(0,l.yg)("h4",{id:"request-body-1"},"Request Body"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "text": "The movie was terrible, I wasted two hours of my life."\n}\n')),(0,l.yg)("table",null,(0,l.yg)("thead",{parentName:"table"},(0,l.yg)("tr",{parentName:"thead"},(0,l.yg)("th",{parentName:"tr",align:null},"Field"),(0,l.yg)("th",{parentName:"tr",align:null},"Type"),(0,l.yg)("th",{parentName:"tr",align:null},"Required"),(0,l.yg)("th",{parentName:"tr",align:null},"Description"))),(0,l.yg)("tbody",{parentName:"table"},(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("inlineCode",{parentName:"td"},"text")),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"Yes"),(0,l.yg)("td",{parentName:"tr",align:null},"Text to analyze")))),(0,l.yg)("h4",{id:"response-2"},"Response"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "prediction": "negative",\n  "inference_time_ms": 15.23,\n  "model": "DistilBERT"\n}\n')),(0,l.yg)("table",null,(0,l.yg)("thead",{parentName:"table"},(0,l.yg)("tr",{parentName:"thead"},(0,l.yg)("th",{parentName:"tr",align:null},"Field"),(0,l.yg)("th",{parentName:"tr",align:null},"Type"),(0,l.yg)("th",{parentName:"tr",align:null},"Description"))),(0,l.yg)("tbody",{parentName:"table"},(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("inlineCode",{parentName:"td"},"prediction")),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},'"positive" or "negative"')),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("inlineCode",{parentName:"td"},"inference_time_ms")),(0,l.yg)("td",{parentName:"tr",align:null},"float"),(0,l.yg)("td",{parentName:"tr",align:null},"Time taken for inference")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("inlineCode",{parentName:"td"},"model")),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"Model used for prediction")))),(0,l.yg)("h4",{id:"example-2"},"Example"),(0,l.yg)("p",null,(0,l.yg)("strong",{parentName:"p"},"cURL:")),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-bash"},'curl -X POST http://localhost:8000/predict-dl \\\n  -H "Content-Type: application/json" \\\n  -d \'{"text": "The movie was terrible, I wasted two hours of my life."}\'\n')),(0,l.yg)("p",null,(0,l.yg)("strong",{parentName:"p"},"Python:")),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-python"},"import requests\n\nresponse = requests.post(\n    \"http://localhost:8000/predict-dl\",\n    json={\"text\": \"The movie was terrible, I wasted two hours of my life.\"}\n)\nprint(response.json())\n# {'prediction': 'negative', 'inference_time_ms': 15.23, 'model': 'DistilBERT'}\n")),(0,l.yg)("hr",null),(0,l.yg)("h2",{id:"error-handling"},"Error Handling"),(0,l.yg)("h3",{id:"model-not-available"},"Model Not Available"),(0,l.yg)("p",null,"If a model hasn't been loaded (missing model file), you'll receive:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "detail": "ML Model not available"\n}\n')),(0,l.yg)("p",null,(0,l.yg)("strong",{parentName:"p"},"HTTP Status"),": 503 Service Unavailable"),(0,l.yg)("h3",{id:"invalid-request"},"Invalid Request"),(0,l.yg)("p",null,"If the request body is malformed:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "detail": [\n    {\n      "loc": ["body", "text"],\n      "msg": "field required",\n      "type": "value_error.missing"\n    }\n  ]\n}\n')),(0,l.yg)("p",null,(0,l.yg)("strong",{parentName:"p"},"HTTP Status"),": 422 Unprocessable Entity"),(0,l.yg)("hr",null),(0,l.yg)("h2",{id:"batch-processing-example"},"Batch Processing Example"),(0,l.yg)("p",null,"For processing multiple texts, loop through your data:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-python"},'import requests\nfrom concurrent.futures import ThreadPoolExecutor\n\ntexts = [\n    "Great product, highly recommend!",\n    "Terrible experience, never again.",\n    "It was okay, nothing special.",\n    "Absolutely fantastic service!",\n    "Waste of money."\n]\n\ndef predict(text):\n    response = requests.post(\n        "http://localhost:8000/predict-ml",\n        json={"text": text}\n    )\n    return response.json()\n\n# Sequential processing\nresults = [predict(text) for text in texts]\n\n# Parallel processing (faster)\nwith ThreadPoolExecutor(max_workers=10) as executor:\n    results = list(executor.map(predict, texts))\n\nfor text, result in zip(texts, results):\n    print(f"{text[:30]}... -> {result[\'prediction\']}")\n')),(0,l.yg)("hr",null),(0,l.yg)("h2",{id:"openapi-documentation"},"OpenAPI Documentation"),(0,l.yg)("p",null,"FastAPI automatically generates interactive API documentation:"),(0,l.yg)("ul",null,(0,l.yg)("li",{parentName:"ul"},(0,l.yg)("strong",{parentName:"li"},"Swagger UI"),": http://localhost:8000/docs"),(0,l.yg)("li",{parentName:"ul"},(0,l.yg)("strong",{parentName:"li"},"ReDoc"),": http://localhost:8000/redoc")),(0,l.yg)("p",null,"These provide an interactive interface to test endpoints directly in your browser."),(0,l.yg)("hr",null),(0,l.yg)("h2",{id:"rate-limiting"},"Rate Limiting"),(0,l.yg)("p",null,"The current implementation does not include rate limiting. For production, consider:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-python"},'from slowapi import Limiter\nfrom slowapi.util import get_remote_address\n\nlimiter = Limiter(key_func=get_remote_address)\n\n@app.post("/predict-ml")\n@limiter.limit("100/minute")\ndef predict_ml(request: Request, body: PredictionRequest):\n    # ...\n')),(0,l.yg)("hr",null),(0,l.yg)("h2",{id:"response-times"},"Response Times"),(0,l.yg)("p",null,"Expected response times under normal load:"),(0,l.yg)("table",null,(0,l.yg)("thead",{parentName:"table"},(0,l.yg)("tr",{parentName:"thead"},(0,l.yg)("th",{parentName:"tr",align:null},"Endpoint"),(0,l.yg)("th",{parentName:"tr",align:null},"Typical Latency"),(0,l.yg)("th",{parentName:"tr",align:null},"99th Percentile"))),(0,l.yg)("tbody",{parentName:"table"},(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("inlineCode",{parentName:"td"},"/healthcheck")),(0,l.yg)("td",{parentName:"tr",align:null},"<5ms"),(0,l.yg)("td",{parentName:"tr",align:null},"<10ms")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("inlineCode",{parentName:"td"},"/predict-ml")),(0,l.yg)("td",{parentName:"tr",align:null},"<1ms"),(0,l.yg)("td",{parentName:"tr",align:null},"<5ms")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("inlineCode",{parentName:"td"},"/predict-dl")),(0,l.yg)("td",{parentName:"tr",align:null},"~15ms"),(0,l.yg)("td",{parentName:"tr",align:null},"~50ms")))),(0,l.yg)("hr",null),(0,l.yg)("h2",{id:"sdk-examples"},"SDK Examples"),(0,l.yg)("h3",{id:"python-client-class"},"Python Client Class"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-python"},'import requests\nfrom typing import Literal\n\nclass SentimentClient:\n    def __init__(self, base_url: str = "http://localhost:8000"):\n        self.base_url = base_url\n\n    def healthcheck(self) -> dict:\n        response = requests.get(f"{self.base_url}/healthcheck")\n        return response.json()\n\n    def predict(\n        self,\n        text: str,\n        model: Literal["ml", "dl"] = "ml"\n    ) -> dict:\n        endpoint = f"/predict-{model}"\n        response = requests.post(\n            f"{self.base_url}{endpoint}",\n            json={"text": text}\n        )\n        return response.json()\n\n# Usage\nclient = SentimentClient()\nprint(client.healthcheck())\nprint(client.predict("This is great!", model="ml"))\nprint(client.predict("This is terrible!", model="dl"))\n')),(0,l.yg)("h3",{id:"javascripttypescript-client"},"JavaScript/TypeScript Client"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-typescript"},'class SentimentClient {\n  constructor(private baseUrl: string = "http://localhost:8000") {}\n\n  async healthcheck(): Promise<HealthCheckResponse> {\n    const response = await fetch(`${this.baseUrl}/healthcheck`);\n    return response.json();\n  }\n\n  async predict(\n    text: string,\n    model: "ml" | "dl" = "ml",\n  ): Promise<PredictionResponse> {\n    const response = await fetch(`${this.baseUrl}/predict-${model}`, {\n      method: "POST",\n      headers: { "Content-Type": "application/json" },\n      body: JSON.stringify({ text }),\n    });\n    return response.json();\n  }\n}\n\n// Usage\nconst client = new SentimentClient();\nconst health = await client.healthcheck();\nconst prediction = await client.predict("This is amazing!", "ml");\n')))}d.isMDXComponent=!0}}]);